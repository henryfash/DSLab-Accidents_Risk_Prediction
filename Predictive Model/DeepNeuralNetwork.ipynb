{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "42"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def reshape_by_catagory(array, category, SEQ=2):\n",
    "    # l=[]\n",
    "    # if category!='geohash' and  category!='NLP' :\n",
    "    #     b = array[0:-14]\n",
    "    #     for i in range(SEQ):\n",
    "    #         c = b[i*25:i*25+25]\n",
    "    #         if category == 'traffic':\n",
    "    #             #d = np.concatenate((c[0:9],c[-5:]),axis=1)\n",
    "    #             d = np.concatenate([c[1:2],c[3:10]],axis=1)\n",
    "    #         elif category=='weather':\n",
    "    #             d = c[10:-5]\n",
    "    #         elif category=='time':\n",
    "    #             d = np.concatenate([c[0:1],c[2:3],c[-5:]],axis=1)\n",
    "    #         else:\n",
    "    #             d = c\n",
    "    #         l.append(d)\n",
    "    #     n = np.concatenate(l,axis=1)\n",
    "    #     #if category!='no_geohash':\n",
    "    #     #    return np.concatenate((n,array[-14:]),axis=1)\n",
    "    #     return n\n",
    "    if category=='NLP':\n",
    "        return array[-100:]\n",
    "    elif category=='TimeVariant':\n",
    "        array = array[0:-114]\n",
    "        return array.reshape((SEQ,int(array.shape[0]/SEQ)))\n",
    "    else:\n",
    "        return array[-114:-100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "class AccidentDataset(data.Dataset):\n",
    "    def __init__(self, X_npy_files: [str], y_npy_files: [str]):\n",
    "        self.X_data = np.concatenate([np.load(f, allow_pickle=True) for f in X_npy_files], axis=0)\n",
    "        self.y_data = np.concatenate([np.load(f, allow_pickle=True) for f in y_npy_files], axis=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        elemX = self.X_data[item, :-1]\n",
    "        geo_code = self.X_data[item, -1]\n",
    "        time_variant = reshape_by_catagory(elemX, \"TimeVariant\", SEQ=8)\n",
    "        geohash2vec = reshape_by_catagory(elemX, \"NLP\")\n",
    "        poi = reshape_by_catagory(elemX, \"geohash\")\n",
    "        elemY = self.y_data[item]\n",
    "\n",
    "        # print('shapes')\n",
    "        # print('elemX', elemX.shape)\n",
    "        # print('time_variant', time_variant.shape)\n",
    "        # print('desc2vec', desc2vec.shape)\n",
    "        # print('poi', poi.shape)\n",
    "        # print('geocode', geo_code)\n",
    "        # sys.exit()\n",
    "\n",
    "        sample = {\n",
    "            'time_variant': torch.tensor(time_variant.astype(np.float), dtype=torch.float),\n",
    "            'geohash2vec': torch.tensor(geohash2vec.astype(np.float), dtype=torch.float),\n",
    "            'poi': torch.tensor(poi.astype(np.float), dtype=torch.float),\n",
    "            'geo_code': torch.tensor(geo_code),\n",
    "            'y': torch.tensor(elemY)\n",
    "        }\n",
    "\n",
    "        return sample\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "class DeepNeuralNetwork(pl.LightningModule):\n",
    "    def __init__(self, cities: [str], *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.cities = cities\n",
    "        self.final_dense_layers =  nn.Sequential(\n",
    "            nn.Linear(139, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, tv, g2v, poi, gcode):\n",
    "        # gcode is single 1x1 element so ignoring\n",
    "        fc_inp = torch.cat((tv[:, -1], g2v, poi), dim=1)\n",
    "        return self.final_dense_layers(fc_inp)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "        return [optimizer]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = AccidentDataset(\n",
    "            X_npy_files=[f\"../data_files/dataset/X_train_{city}.npy\" for city in self.cities],\n",
    "            y_npy_files=[f\"../data_files/dataset/y_train_{city}.npy\" for city in self.cities],\n",
    "        )\n",
    "        dataloader = data.DataLoader(dataset, batch_size=1024, shuffle=True, num_workers=4, pin_memory=True)\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = AccidentDataset(\n",
    "            X_npy_files=[f\"../data_files/dataset/X_test_{city}.npy\" for city in self.cities],\n",
    "            y_npy_files=[f\"../data_files/dataset/y_test_{city}.npy\" for city in self.cities],\n",
    "        )\n",
    "        dataloader = data.DataLoader(dataset, batch_size=128, num_workers=4, pin_memory=True)\n",
    "        return dataloader\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        out =  self.forward(tv=batch['time_variant'], poi=batch['poi'], g2v=batch['geohash2vec'], gcode=batch['geo_code'])\n",
    "        loss = self.loss(out, batch['y'])\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        out =  self.forward(tv=batch['time_variant'], poi=batch['poi'], g2v=batch['geohash2vec'], gcode=batch['geo_code'])\n",
    "        acc =  (torch.argmax(out, dim=1) == batch['y']).count_nonzero() / (len(batch['y']) * 1.0)\n",
    "        loss = self.loss(out, batch['y'])\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=False, logger=True)\n",
    "        self.log(\"val_acc\", acc, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {\"val_batch_loss\": loss, \"val_batch_acc\": acc}\n",
    "\n",
    "    def on_train_end(self):\n",
    "        y_pred, y_true = self.predict(return_labels=True)\n",
    "        print(\"Train Stopped: Printing F1 Score (of Validation) ...\")\n",
    "        print(classification_report(y_true, y_pred))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, return_labels=True):\n",
    "        dataloader = self.val_dataloader()\n",
    "        predY: [int] = []\n",
    "        actualY: [int] = []\n",
    "        for batch in dataloader:\n",
    "            tv, poi, geohash2vec, geo_code, y = batch['time_variant'].to(self.device), \\\n",
    "                                             batch['poi'].to(self.device), \\\n",
    "                                             batch['geohash2vec'].to(self.device), \\\n",
    "                                             batch['geo_code'].to(self.device), \\\n",
    "                                             batch['y'].to(self.device)\n",
    "\n",
    "\n",
    "            y_hat = self.forward(tv=tv, poi=poi, g2v=geohash2vec, gcode=geo_code)\n",
    "            class_predictions = torch.argmax(y_hat, dim=1)\n",
    "            predY.extend(class_predictions.tolist())\n",
    "            actualY.extend(y.tolist())\n",
    "\n",
    "        if return_labels:\n",
    "            return predY, actualY\n",
    "\n",
    "        return predY"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type             | Params\n",
      "--------------------------------------------------------\n",
      "0 | final_dense_layers | Sequential       | 219 K \n",
      "1 | loss               | CrossEntropyLoss | 0     \n",
      "--------------------------------------------------------\n",
      "219 K     Trainable params\n",
      "0         Non-trainable params\n",
      "219 K     Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training ...\n",
      "Train Stopped: Printing F1 Score (of Validation) ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92     26137\n",
      "           1       0.71      0.30      0.42      5341\n",
      "\n",
      "    accuracy                           0.86     31478\n",
      "   macro avg       0.79      0.63      0.67     31478\n",
      "weighted avg       0.84      0.86      0.83     31478\n",
      "\n",
      "Completed training!\n"
     ]
    }
   ],
   "source": [
    "print(\"Begin training ...\")\n",
    "model = DeepNeuralNetwork(cities=[\"Atlanta\", \"Austin\", \"Charlotte\", \"Dallas\", \"Houston\", \"LosAngeles\"])\n",
    "trainer = pl.Trainer(\n",
    "            gpus=1,\n",
    "            num_nodes=1,\n",
    "            deterministic=True,\n",
    "            max_epochs=10,\n",
    "            progress_bar_refresh_rate=0, # comment to enable progress bar\n",
    "        )\n",
    "trainer.fit(model)\n",
    "print(\"Completed training!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type             | Params\n",
      "--------------------------------------------------------\n",
      "0 | final_dense_layers | Sequential       | 219 K \n",
      "1 | loss               | CrossEntropyLoss | 0     \n",
      "--------------------------------------------------------\n",
      "219 K     Trainable params\n",
      "0         Non-trainable params\n",
      "219 K     Total params\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type             | Params\n",
      "--------------------------------------------------------\n",
      "0 | final_dense_layers | Sequential       | 219 K \n",
      "1 | loss               | CrossEntropyLoss | 0     \n",
      "--------------------------------------------------------\n",
      "219 K     Trainable params\n",
      "0         Non-trainable params\n",
      "219 K     Total params\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type             | Params\n",
      "--------------------------------------------------------\n",
      "0 | final_dense_layers | Sequential       | 219 K \n",
      "1 | loss               | CrossEntropyLoss | 0     \n",
      "--------------------------------------------------------\n",
      "219 K     Trainable params\n",
      "0         Non-trainable params\n",
      "219 K     Total params\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type             | Params\n",
      "--------------------------------------------------------\n",
      "0 | final_dense_layers | Sequential       | 219 K \n",
      "1 | loss               | CrossEntropyLoss | 0     \n",
      "--------------------------------------------------------\n",
      "219 K     Trainable params\n",
      "0         Non-trainable params\n",
      "219 K     Total params\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type             | Params\n",
      "--------------------------------------------------------\n",
      "0 | final_dense_layers | Sequential       | 219 K \n",
      "1 | loss               | CrossEntropyLoss | 0     \n",
      "--------------------------------------------------------\n",
      "219 K     Trainable params\n",
      "0         Non-trainable params\n",
      "219 K     Total params\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type             | Params\n",
      "--------------------------------------------------------\n",
      "0 | final_dense_layers | Sequential       | 219 K \n",
      "1 | loss               | CrossEntropyLoss | 0     \n",
      "--------------------------------------------------------\n",
      "219 K     Trainable params\n",
      "0         Non-trainable params\n",
      "219 K     Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training ... Dataset: Atlanta\n",
      "Train Stopped: Printing F1 Score (of Validation) ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90      1984\n",
      "           1       0.72      0.36      0.48       531\n",
      "\n",
      "    accuracy                           0.84      2515\n",
      "   macro avg       0.78      0.66      0.69      2515\n",
      "weighted avg       0.82      0.84      0.81      2515\n",
      "\n",
      "Begin training ... Dataset: Austin\n",
      "Train Stopped: Printing F1 Score (of Validation) ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      3863\n",
      "           1       0.67      0.62      0.64       801\n",
      "\n",
      "    accuracy                           0.88      4664\n",
      "   macro avg       0.80      0.78      0.79      4664\n",
      "weighted avg       0.88      0.88      0.88      4664\n",
      "\n",
      "Begin training ... Dataset: Charlotte\n",
      "Train Stopped: Printing F1 Score (of Validation) ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      3446\n",
      "           1       0.71      0.52      0.60       939\n",
      "\n",
      "    accuracy                           0.85      4385\n",
      "   macro avg       0.79      0.73      0.75      4385\n",
      "weighted avg       0.84      0.85      0.84      4385\n",
      "\n",
      "Begin training ... Dataset: Dallas\n",
      "Train Stopped: Printing F1 Score (of Validation) ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94      4723\n",
      "           1       0.52      0.29      0.37       622\n",
      "\n",
      "    accuracy                           0.89      5345\n",
      "   macro avg       0.72      0.63      0.65      5345\n",
      "weighted avg       0.87      0.89      0.87      5345\n",
      "\n",
      "Begin training ... Dataset: Houston\n",
      "Train Stopped: Printing F1 Score (of Validation) ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      7326\n",
      "           1       0.72      0.33      0.45      1111\n",
      "\n",
      "    accuracy                           0.89      8437\n",
      "   macro avg       0.81      0.65      0.70      8437\n",
      "weighted avg       0.88      0.89      0.88      8437\n",
      "\n",
      "Begin training ... Dataset: LosAngeles\n",
      "Train Stopped: Printing F1 Score (of Validation) ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.87      4795\n",
      "           1       0.52      0.55      0.53      1337\n",
      "\n",
      "    accuracy                           0.79      6132\n",
      "   macro avg       0.70      0.70      0.70      6132\n",
      "weighted avg       0.79      0.79      0.79      6132\n",
      "\n",
      "Completed training!\n"
     ]
    }
   ],
   "source": [
    "for city in [\"Atlanta\", \"Austin\", \"Charlotte\", \"Dallas\", \"Houston\", \"LosAngeles\"]:\n",
    "    print(f\"Begin training ... Dataset: {city}\")\n",
    "    model = DeepNeuralNetwork(cities=[city])\n",
    "    trainer = pl.Trainer(\n",
    "                gpus=1,\n",
    "                num_nodes=1,\n",
    "                deterministic=True,\n",
    "                max_epochs=10,\n",
    "                progress_bar_refresh_rate=0, # comment to enable progress bar\n",
    "            )\n",
    "    trainer.fit(model)\n",
    "print(\"Completed training!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}